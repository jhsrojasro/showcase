<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Workshop #1 # Convolutional Neural Networks: # Aplicación de redes neuronales para clasificar imagenes segun el clima.
Introducción # Red neuronal convolucional (Convolutional Neural Network) # Es un algoritmo de aprendizaje profundo que toma como entrada una imagen, asigna importancia a varios aspectos u objetos de la misma y los diferencia. Lo consigue a través de la aplicación de filtros relevantes. La arquitectura de una CNN es análoga a los patrones de conectividad de neuronas del cerebro humano y fue inspirada en la organización de la corteza visual."><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:title" content><meta property="og:description" content="Workshop #1 # Convolutional Neural Networks: # Aplicación de redes neuronales para clasificar imagenes segun el clima.
Introducción # Red neuronal convolucional (Convolutional Neural Network) # Es un algoritmo de aprendizaje profundo que toma como entrada una imagen, asigna importancia a varios aspectos u objetos de la misma y los diferencia. Lo consigue a través de la aplicación de filtros relevantes. La arquitectura de una CNN es análoga a los patrones de conectividad de neuronas del cerebro humano y fue inspirada en la organización de la corteza visual."><meta property="og:type" content="article"><meta property="og:url" content="https://jhsrojasro.github.io/showcase/docs/shortcodes/workshop/"><meta property="article:section" content="docs"><meta property="article:modified_time" content="2022-04-06T09:14:08-05:00"><title>Workshop | Showcase Template</title><link rel=manifest href=/showcase/manifest.json><link rel=icon href=/showcase/favicon.png type=image/x-icon><link rel=stylesheet href=/showcase/book.min.ab46de3e725a6415339a37bba23a0067534a37289b063c9f8d011515a63097a8.css integrity="sha256-q0bePnJaZBUzmje7ojoAZ1NKNyibBjyfjQEVFaYwl6g=" crossorigin=anonymous><script defer src=/showcase/flexsearch.min.js></script>
<script defer src=/showcase/en.search.min.4c01b89da341518da51a9c9593057ffc2ea75b01bba94732ebeaf33c27756a4a.js integrity="sha256-TAG4naNBUY2lGpyVkwV//C6nWwG7qUcy6+rzPCd1ako=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/showcase/><span>Showcase Template</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li class=book-section-flat><span>Shortcodes</span><ul><li><a href=/showcase/docs/shortcodes/integrantes/>Integrantes</a></li><li><a href=/showcase/docs/shortcodes/logs/>Logs</a></li><li><input type=checkbox id=section-317ff9256596583937fd0dc8b10b1dfa class=toggle>
<label for=section-317ff9256596583937fd0dc8b10b1dfa class="flex justify-between"><a role=button>Ml5</a></label><ul><li><a href=/showcase/docs/shortcodes/ml5/BodyPrix/>Body Prix</a></li><li><a href=/showcase/docs/shortcodes/ml5/FaceMesh/>Face Mesh</a></li><li><a href=/showcase/docs/shortcodes/ml5/HandPose/>Hand Pose</a></li><li><a href=/showcase/docs/shortcodes/ml5/image-classification/>Image Classification</a></li><li><a href=/showcase/docs/shortcodes/ml5/PoseNet/>Pose Net</a></li></ul></li><li><input type=checkbox id=section-ec67a64aba70b9df3d2a9acd6c92e3bc class=toggle>
<label for=section-ec67a64aba70b9df3d2a9acd6c92e3bc class="flex justify-between"><a href=/showcase/docs/shortcodes/p5/>P5</a></label><ul><li><a href=/showcase/docs/shortcodes/p5/div/>Div</a></li></ul></li><li><a href=/showcase/docs/shortcodes/workshop/ class=active>Workshop</a></li><li><input type=checkbox id=section-699c85deb1d28081c80315a3708d5473 class=toggle>
<label for=section-699c85deb1d28081c80315a3708d5473 class="flex justify-between"><a role=button>Workshop2</a></label><ul><li><a href=/showcase/docs/shortcodes/workshop2/3dBrush/>3d Brush</a></li><li><a href=/showcase/docs/shortcodes/workshop2/softwareRendering/>Software Rendering</a></li></ul></li><li><input type=checkbox id=section-e5d4e557e211471385c7d15285ea39e0 class=toggle>
<label for=section-e5d4e557e211471385c7d15285ea39e0 class="flex justify-between"><a role=button>Workshop3</a></label><ul><li><a href=/showcase/docs/shortcodes/workshop3/link-to-repository/>Link to Repository</a></li></ul></li></ul></li></ul><ul><li><a href=/showcase/posts/>Blog</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/showcase/svg/menu.svg class=book-icon alt=Menu></label>
<strong>Workshop</strong>
<label for=toc-control><img src=/showcase/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#workshop-1>Workshop #1</a><ul><li><a href=#convolutional-neural-networks>Convolutional Neural Networks:</a><ul><li><a href=#introducción>Introducción</a></li><li><a href=#contexto>Contexto</a></li><li><a href=#resultados>Resultados</a></li><li><a href=#conclusiones>Conclusiones</a></li><li><a href=#trabajo-futuro>Trabajo Futuro</a></li><li><a href=#notebook>Notebook</a></li><li><a href=#referencias>Referencias</a></li></ul></li></ul></li></ul></nav></aside></header><article class=markdown><h1 id=workshop-1>Workshop #1
<a class=anchor href=#workshop-1>#</a></h1><h2 id=convolutional-neural-networks>Convolutional Neural Networks:
<a class=anchor href=#convolutional-neural-networks>#</a></h2><p>Aplicación de redes neuronales para clasificar imagenes segun el clima.</p><h3 id=introducción>Introducción
<a class=anchor href=#introducci%c3%b3n>#</a></h3><h4 id=red-neuronal-convolucional-convolutional-neural-network>Red neuronal convolucional (Convolutional Neural Network)
<a class=anchor href=#red-neuronal-convolucional-convolutional-neural-network>#</a></h4><p>Es un algoritmo de aprendizaje profundo que toma como entrada una imagen, asigna importancia a varios aspectos u objetos de la misma y los diferencia. Lo consigue a través de la aplicación de filtros relevantes. La arquitectura de una CNN es análoga a los patrones de conectividad de neuronas del cerebro humano y fue inspirada en la organización de la corteza visual.</p><p>Una red neuronal convolucional puede capturar con éxito las dependencias espaciales y temporales de una imagen mediante la aplicación de filtros. La arquitectura realiza un mejor ajuste al conjunto de datos de la imagen debido a la reducción en la cantidad de parámetros involucrados y la reutilización de los pesos. En otras palabras, la red puede ser entrenada para comprender mejor la sofisticación de la imagen.</p><p>Imagen de Entrada:</p><img width=345 alt=dataset src=https://user-images.githubusercontent.com/55771991/161895985-e847bcc6-010f-41bc-a251-17c9d5c1bd55.png><p>En la figura, tenemos una imagen RGB que ha sido separada por sus tres planos de color: rojo, verde y azul.
Desde el punto de vista computacional se volverían intensas las cosas una vez que las imágenes alcanzarán dimensiones de 8K (7680 × 4320). El papel de redes convolucionales es reducir las imágenes a una forma que sea más fácil de procesar, sin perder características que son críticas para obtener una buena predicción.</p><p>Capa de convolución: el kernel:</p><img width=345 alt=dataset src=https://miro.medium.com/max/1052/1*GcI7G-JLAQiEoCON7xFbhg.gif><p>La sección verde se asemeja a nuestra imagen de entrada de 5x5x1. El elemento involucrado en la realización de la operación de convolución en la primera parte de una Capa Convolucional se llama Kernel/Filtro, K, representado en color amarillo. Hemos seleccionado K como matriz de 3x3x1.</p><img width=345 alt=dataset src=https://miro.medium.com/max/1400/1*ciDgQEjViWLnCbmX-EeSrA.gif><p>En el caso de imágenes con múltiples canales (por ejemplo, RGB), el Kernel tiene la misma profundidad que la de la imagen de entrada. La multiplicación de matrices se realiza entre Kn e In stack ([K1, I1]; [K2, I2]; [K3, I3]) y todos los resultados se suman con el sesgo para darnos una salida de características contorneadas de un canal aplastado.</p><img width=345 alt=dataset src=https://miro.medium.com/max/790/1*1VJDP6qDY9-ExTuQVEOlVg.gif><p>El objetivo de la operación de convolución es extraer las características de alto nivel, como los bordes, de la imagen de entrada. No necesitan estar limitadas a una sola capa convolucional. Convencionalmente, el primer ConvLayer es responsable de capturar las características de bajo nivel, como los bordes, el color, la orientación del degradado, etc. Con capas adicionales, la arquitectura también se adapta a las características de alto nivel, brindándonos una red que tiene la comprensión completa de imágenes en el conjunto de datos.</p><p>Hay dos tipos de resultados para la operación: uno en el que la característica convolucionada se reduce en dimensionalidad en comparación con la entrada, y el otro en el que la dimensionalidad aumenta o permanece igual. Esto se hace aplicando Valid Padding en el caso del primero, o Same Padding en el caso del segundo.</p><img width=345 alt=dataset src=https://miro.medium.com/max/790/1*nYf_cUIHFEWU1JXGwnz-Ig.gif><p>Cuando aumentamos la imagen de 5x5x1 a una imagen de 6x6x1 y luego aplicamos el kernel de 3x3x1 sobre ella, encontramos que la matriz convolucionada resulta ser de dimensiones 5x5x1. De ahí el nombre: el Same Padding.</p><p>Por otro lado, si realizamos la misma operación sin relleno, se nos presenta una matriz que tiene las dimensiones del propio Kernel (3x3x1): Valid Padding.</p><h3 id=contexto>Contexto
<a class=anchor href=#contexto>#</a></h3><h4 id=conjunto-de-datos>Conjunto de datos
<a class=anchor href=#conjunto-de-datos>#</a></h4><p>El conjunto de datos utilizado para entrenar la red neuronal fue compartido en la plataforma Kaggle y contiene 6862 imágenes de diferentes tipos de clima, es comúnmente usado para implementar tareas de clasificación de clima basado en imágenes. Las fotos están divididas en 11 clases.<br><img width=345 alt=dataset src=https://user-images.githubusercontent.com/39863678/161894269-8e193d10-4a1e-4d60-8e65-787f5d4a1b55.PNG></p><h4 id=modelos-de-redes-neuronales-convolucionales>Modelos de redes neuronales convolucionales
<a class=anchor href=#modelos-de-redes-neuronales-convolucionales>#</a></h4><p>Se experimentó con dos arquitecturas de redes neuronales convolucionales: EfficientNet y DenseNet.</p><h5 id=efficientnet>EfficientNet
<a class=anchor href=#efficientnet>#</a></h5><img width=547 alt=modulos src=https://user-images.githubusercontent.com/39863678/161894334-5861b7ac-6c3f-4fef-93f4-1bd3d38db0d6.PNG>
<img width=562 alt="efficientNet b7" src=https://user-images.githubusercontent.com/39863678/161894363-bf2332f2-874c-4b11-9558-807272d3841c.PNG><h5 id=densenet>DenseNet
<a class=anchor href=#densenet>#</a></h5><img width=422 alt=denseNet src=https://user-images.githubusercontent.com/39863678/161894387-6a4c6adc-e62e-4654-bef9-11e379c2f9d1.PNG><h3 id=resultados>Resultados
<a class=anchor href=#resultados>#</a></h3><p>Del entrenamiento de ambos modelos, se obtuvieron las siguientes métricas:</p><table><thead><tr><th>Modelo</th><th>Pérdida</th><th>Accuracy</th></tr></thead><tbody><tr><td>EfficientNet B7</td><td>0.68872</td><td>76.04%</td></tr><tr><td>DenseNet201</td><td>0.58884</td><td>84.34%</td></tr></tbody></table>Es claro que el modelo DenseNet tuvo mejor desempeño en el conjunto de datos de entrenamiento, sin embargo en la prueba que se planteó con imágenes de la Universidad, las clasificaciones de este modelo no fueron tan buenas como las de EfficientNet:<h5 id=densenet-1>DenseNet
<a class=anchor href=#densenet-1>#</a></h5><img width=512 alt="prediccion denseNet" src=https://user-images.githubusercontent.com/39863678/161894404-dedb773e-2fd9-414c-aebc-3c23b7fe8ab4.PNG><h5 id=efficientnet-1>EfficientNet
<a class=anchor href=#efficientnet-1>#</a></h5><img width=415 alt="prediccion efficientNet" src=https://user-images.githubusercontent.com/39863678/161894416-5f2028cb-d7b5-4e85-ac5e-61295c192d7d.PNG><p>El modelo DenseNet presenta un claro sobreajuste al conjunto de datos, no generaliza bien la función clasificadora.</p><h3 id=conclusiones>Conclusiones
<a class=anchor href=#conclusiones>#</a></h3><ul><li>Las redes neuronales convolucionales son aproximadores de funciones con los que se puede resolver el problema de clasificación de imágenes según el clima presente.</li><li>Se entrenaron dos modelos de redes neuronales populares usando un conjunto de datos público.</li><li>Uno de los modelos entrenados pudo clasificar parcialmente las imágenes de prueba de la universidad.</li></ul><h3 id=trabajo-futuro>Trabajo Futuro
<a class=anchor href=#trabajo-futuro>#</a></h3><p>Como trabajo futuro se recomiendan los siguientes caminos:</p><ul><li>Probar con otras arquitecturas de redes neuronales convolucionales.</li><li>Probar diferentes configuraciones de hiper parámetros de los modelos para determinar si se pueden obtener mejores resultados.</li><li>Probar otras técnicas de clasificación de imágenes</li><li>Migrar los modelos a tensorflow.js y ml5 para facilitar su visualización en entornos web.</li></ul><h3 id=notebook>Notebook
<a class=anchor href=#notebook>#</a></h3><p><a href="https://colab.research.google.com/drive/1b9sXwW_IOtLZ4BzwTOUcfQmpo7fS5M_u?usp=sharing">https://colab.research.google.com/drive/1b9sXwW_IOtLZ4BzwTOUcfQmpo7fS5M_u?usp=sharing</a></p><h3 id=referencias>Referencias
<a class=anchor href=#referencias>#</a></h3><ul><li>Chahar, Vijay & Jaiswal, Aayush & Gianchandani, Neha & Singh, Dilbag & Kaur, Manjit. (2020). Classification of the COVID-19 infected patients using DenseNet201 based deep transfer learning. Journal of biomolecular Structure & Dynamics. 39. 10.1080/07391102.2020.1788642.</li><li>Sumit Saha. A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way. Towars Data Science. 2018</li></ul></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/visualcomputing/showcase/commit/6fa5864c3761aa3aba273ef04df93b48d0fa0d2e title='Last modified by Sebastian Rojas | April 6, 2022' target=_blank rel=noopener><img src=/showcase/svg/calendar.svg class=book-icon alt=Calendar>
<span>April 6, 2022</span></a></div></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#workshop-1>Workshop #1</a><ul><li><a href=#convolutional-neural-networks>Convolutional Neural Networks:</a><ul><li><a href=#introducción>Introducción</a></li><li><a href=#contexto>Contexto</a></li><li><a href=#resultados>Resultados</a></li><li><a href=#conclusiones>Conclusiones</a></li><li><a href=#trabajo-futuro>Trabajo Futuro</a></li><li><a href=#notebook>Notebook</a></li><li><a href=#referencias>Referencias</a></li></ul></li></ul></li></ul></nav></div></aside></main></body></html>